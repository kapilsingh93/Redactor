{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9159f89-63f6-4ca7-a05c-80d34624a861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "brt = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "def infer_llm(text,context=None):\n",
    "    body = json.dumps({\n",
    "        \"prompt\": f\"\\n\\n\\\n",
    "        Human: Using the context key and the value given below, strictly classify the value in one of the \\\n",
    "        following classes. Please respond with the following class labels only i.e PERSON_NAME, ADDRESS, PHONE, OTHER. \\\n",
    "        Class definitions: \\n\\\n",
    "        PERSON_NAME: Represents the name of an actual person. NAMES don't include the names of organizations or companies.\\n\\\n",
    "        ADDRESS: Reprents the physical address of a person/organization.\\n \\\n",
    "        PHONE: Represents a phone number of a person/organization.\\n \\\n",
    "        OTHER: Represents something else. \\n\\n\\n\\\n",
    "        Keys: {context if context else 'Unknown'}\\n\\\n",
    "        Value: {text}\\\n",
    "        \\n\\nAssistant:\",\n",
    "        \"max_tokens_to_sample\": 300,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "    })\n",
    "\n",
    "    modelId = 'anthropic.claude-v2:1'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    response = brt.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body.get('completion')\n",
    "\n",
    "# text\n",
    "# print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a88cdc63-ec8e-4c85-9a71-e69255263b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "annotations=[]\n",
    "path='/home/ec2-user/SageMaker/data/FUNSD/dataset/training_data/annotations'\n",
    "for file in os.listdir(path):\n",
    "    if '.json' in file :\n",
    "        with open(f\"{path}/{file}\") as file_in:\n",
    "            annotations.append({\"file\":file,\"annotation\":json.load(file_in)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3ee140f5-c4e3-45ec-836d-edcb5beccf8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [20:09<00:00, 24.19s/it]\n"
     ]
    }
   ],
   "source": [
    "cache={}\n",
    "from tqdm import tqdm\n",
    "for annotation in tqdm(annotations):\n",
    "    for text_box in annotation['annotation']['form']:\n",
    "        # print(text_box)\n",
    "        if 'answer' in text_box['label']:            \n",
    "            contexts=[link for links in text_box['linking'] for link in links if link !=text_box['id']]\n",
    "            contexts=[annotation['annotation']['form'][entity_id]['text'] for entity_id in contexts]\n",
    "\n",
    "            if str(contexts) not in cache:                \n",
    "                result=infer_llm(text_box['text'],contexts)\n",
    "                if 'OTHER' not in result:\n",
    "                    # print(f\"Text: {text_box['text']} .\\n Context: {contexts}\")                    \n",
    "                    # print(result)\n",
    "                    if 'NAME' in result:\n",
    "                        text_box['pii_label']=\"NAME\"\n",
    "                    if 'PHONE' in result:\n",
    "                        text_box['pii_label']=\"PHONE\"\n",
    "                    if 'ADDRESS' in result:\n",
    "                        text_box['pii_label']=\"ADDRESS\"\n",
    "                # cache[str(contexts)]=result\n",
    "            else:\n",
    "                print(f\"Cached response {cache[str(contexts)]}\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6798de55-a240-42c2-943a-26693f8719a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 73584.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity stats in the corpus {'NAME': 127, 'PHONE': 78, 'ADDRESS': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count_map={'NAME':0,'PHONE':0, 'ADDRESS':0}\n",
    "for annotation in tqdm(annotations):\n",
    "    for text_box in annotation['annotation']['form']:\n",
    "        if \"pii_label\" in text_box:\n",
    "            count_map[text_box['pii_label']]+=1\n",
    "print(f\"Entity stats in the corpus {count_map}\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74bf4843-e0e2-4e65-bbb2-99f8e70180ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 73843.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for annotation in tqdm(annotations):\n",
    "    for text_box in annotation['annotation']['form']:\n",
    "         if \"pii_label\" in text_box:\n",
    "            text_box['label']=text_box['pii_label'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0368946-726e-47dc-903e-7c927ebd9d46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 395.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for annotation in tqdm(annotations):\n",
    "    with open(f'{path}/{annotation[\"file\"]}','w') as file_out:\n",
    "        json.dump(annotation['annotation'],file_out)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75741d1a-3560-4f73-bb26-610817ebee04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36b90986-29a9-4760-8a70-fb0c6b107fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:00<00:00, 405.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for annotation in tqdm(annotations):\n",
    "    for text_box in annotation['annotation']['form']:\n",
    "        if text_box['label'] not in {'name','address','phone'}:\n",
    "            text_box['label'] = \"other\"\n",
    "    with open(f'{path}/{annotation[\"file\"]}','w') as file_out:\n",
    "        json.dump(annotation['annotation'],file_out)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9129167d-9a58-4ed7-8c2e-b109dee31db7",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m PATH\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ec2-user/SageMaker/data/FUNSD/dataset/training_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m    \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# for file in os.listdir(PATH+\"images\"):\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     if '.png' in file:\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Visualize annotations for a specific document\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mvisualize_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages/00093726.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mannotations/00070353.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m, in \u001b[0;36mvisualize_annotations\u001b[0;34m(annotations_path, image_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_annotations\u001b[39m(annotations_path, image_path):\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Load annotations for a specific document (change 'document_name.json' to the desired document's JSON file)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(annotations_path) \u001b[38;5;28;01mas\u001b[39;00m file_in:        \n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file_in:\n\u001b[1;32m     12\u001b[0m             annotations \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Extract textbox annotations\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Function to visualize textboxes and their labels\n",
    "def visualize_annotations(annotations_path, image_path):\n",
    "        # Load annotations for a specific document (change 'document_name.json' to the desired document's JSON file)\n",
    "    with open(annotations_path) as file_in:        \n",
    "        for line in file_in:\n",
    "            annotations = json.loads(line)\n",
    "\n",
    "    # Extract textbox annotations\n",
    "    textbox_annotations = annotations['form']\n",
    "\n",
    "    # Load the image using PIL\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Create ImageDraw object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Plot textboxes and their labels\n",
    "    for textbox in textbox_annotations:\n",
    "        label = textbox['label']\n",
    "        coords = textbox['box']\n",
    "        print(coords)\n",
    "        x, y, width, height = coords['x'], coords['y'], coords['width'], coords['height']\n",
    "        \n",
    "        # Draw rectangle patch directly onto the image\n",
    "        draw.rectangle([(x, y), (x + width, y + height)], outline='red')\n",
    "        \n",
    "        # Display label using text annotation\n",
    "        draw.text((x, y - 15), label, fill='red')\n",
    "    \n",
    "    # Display the image using IPython.display\n",
    "    display(img)\n",
    "\n",
    "PATH=\"/home/ec2-user/SageMaker/data/FUNSD/dataset/training_data/\"    \n",
    "# for file in os.listdir(PATH+\"images\"):\n",
    "#     if '.png' in file:\n",
    "# Visualize annotations for a specific document\n",
    "visualize_annotations(PATH+'images/00093726.png', PATH+'annotations/00093726.json')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88841c03-de6a-455e-a120-de9cc8f96bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
